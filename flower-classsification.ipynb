{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":21154,"databundleVersionId":1243559,"sourceType":"competition"}],"dockerImageVersionId":30675,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-31T09:09:52.943164Z","iopub.execute_input":"2024-03-31T09:09:52.943504Z","iopub.status.idle":"2024-03-31T09:09:55.013901Z","shell.execute_reply.started":"2024-03-31T09:09:52.943473Z","shell.execute_reply":"2024-03-31T09:09:55.013122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os\nimport re\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB7\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\nfrom tensorflow.keras.metrics import F1Score\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.optimizers.schedules import CosineDecay\n\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-03-31T09:10:18.156708Z","iopub.execute_input":"2024-03-31T09:10:18.157041Z","iopub.status.idle":"2024-03-31T09:10:35.197389Z","shell.execute_reply.started":"2024-03-31T09:10:18.157012Z","shell.execute_reply":"2024-03-31T09:10:35.196472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU: ', tpu.master())\nexcept ValueError:\n    tpu = None\n    \nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T09:10:35.198787Z","iopub.execute_input":"2024-03-31T09:10:35.199252Z","iopub.status.idle":"2024-03-31T09:10:43.741127Z","shell.execute_reply.started":"2024-03-31T09:10:35.199224Z","shell.execute_reply":"2024-03-31T09:10:43.740325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16 * strategy.num_replicas_in_sync\nTRAIN_SIZE = 12753\nVAL_SIZE = 3712\nTEST_SIZE = 7382","metadata":{"execution":{"iopub.status.busy":"2024-03-31T09:10:43.742020Z","iopub.execute_input":"2024-03-31T09:10:43.742291Z","iopub.status.idle":"2024-03-31T09:10:43.745899Z","shell.execute_reply.started":"2024-03-31T09:10:43.742264Z","shell.execute_reply":"2024-03-31T09:10:43.745235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading the Dataset","metadata":{}},{"cell_type":"code","source":"def decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, [299, 299])            # required shape for Xception\n    image = tf.cast(image, tf.float32)\n    image = (image / 127.5) - 1\n    return image","metadata":{"execution":{"iopub.status.busy":"2024-03-31T09:10:43.747654Z","iopub.execute_input":"2024-03-31T09:10:43.747921Z","iopub.status.idle":"2024-03-31T09:10:43.769419Z","shell.execute_reply.started":"2024-03-31T09:10:43.747894Z","shell.execute_reply":"2024-03-31T09:10:43.768622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_labeled_tfrecord(tfrecord):\n    schema = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'class': tf.io.FixedLenFeature([], tf.int64)\n    }\n    \n    record = tf.io.parse_single_example(tfrecord, schema)\n    \n    image = decode_image(record['image'])\n    label = tf.one_hot(record['class'], 104)\n    \n    return image, label","metadata":{"execution":{"iopub.status.busy":"2024-03-31T09:11:19.794717Z","iopub.execute_input":"2024-03-31T09:11:19.795450Z","iopub.status.idle":"2024-03-31T09:11:19.800522Z","shell.execute_reply.started":"2024-03-31T09:11:19.795409Z","shell.execute_reply":"2024-03-31T09:11:19.799526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_unlabeled_tfrecord(tfrecord):\n    schema = {\n        'id': tf.io.FixedLenFeature([], tf.string),\n        'image': tf.io.FixedLenFeature([], tf.string)\n    }\n    \n    record = tf.io.parse_single_example(tfrecord, schema)\n    \n    image = decode_image(record['image'])\n    \n    return record['id'], image","metadata":{"execution":{"iopub.status.busy":"2024-03-31T09:11:15.666367Z","iopub.execute_input":"2024-03-31T09:11:15.666734Z","iopub.status.idle":"2024-03-31T09:11:15.671694Z","shell.execute_reply.started":"2024-03-31T09:11:15.666704Z","shell.execute_reply":"2024-03-31T09:11:15.670847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dataset(files, testing_set=False, augment=False):\n    ignore_order = tf.data.Options()\n    \n    if not testing_set:\n        ignore_order.experimental_deterministic = False\n        \n    dataset = tf.data.TFRecordDataset(files)\n    dataset = dataset.with_options(ignore_order)\n    \n    if not testing_set:\n        dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n        if augment:\n            dataset = dataset.map(data_augmentation, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n    else:\n        dataset = dataset.map(read_unlabeled_tfrecord, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n        \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2024-03-31T09:11:02.068620Z","iopub.execute_input":"2024-03-31T09:11:02.068991Z","iopub.status.idle":"2024-03-31T09:11:02.075383Z","shell.execute_reply.started":"2024-03-31T09:11:02.068960Z","shell.execute_reply":"2024-03-31T09:11:02.074348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_augmentation(image, label):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n    \n    return image, label","metadata":{"execution":{"iopub.status.busy":"2024-03-31T09:11:40.515388Z","iopub.execute_input":"2024-03-31T09:11:40.516064Z","iopub.status.idle":"2024-03-31T09:11:40.519980Z","shell.execute_reply.started":"2024-03-31T09:11:40.516019Z","shell.execute_reply":"2024-03-31T09:11:40.519139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_file_names(dataset_type):\n    file_names = []\n    pattern = f'/kaggle/input/tpu-getting-started/tfrecords-jpeg-512x512/{dataset_type}/*.tfrec'\n    files = tf.io.gfile.glob(pattern)\n    file_names.extend(files)\n        \n    return file_names","metadata":{"execution":{"iopub.status.busy":"2024-03-31T09:11:03.836885Z","iopub.execute_input":"2024-03-31T09:11:03.837629Z","iopub.status.idle":"2024-03-31T09:11:03.841764Z","shell.execute_reply.started":"2024-03-31T09:11:03.837591Z","shell.execute_reply":"2024-03-31T09:11:03.841004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_training_data():\n    training_file_names = get_file_names('train')\n    dataset = load_dataset(training_file_names, augment=True)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n    return dataset\n\ndef load_val_data():\n    val_file_names = get_file_names('val')\n    dataset = load_dataset(val_file_names)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n    return dataset \n    \ndef load_test_data():\n    test_file_names = get_file_names('test')\n    dataset = load_dataset(test_file_names, testing_set=True)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n    return dataset ","metadata":{"execution":{"iopub.status.busy":"2024-03-31T09:10:53.262921Z","iopub.execute_input":"2024-03-31T09:10:53.263290Z","iopub.status.idle":"2024-03-31T09:10:53.269652Z","shell.execute_reply.started":"2024-03-31T09:10:53.263253Z","shell.execute_reply":"2024-03-31T09:10:53.268691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = load_training_data()\nvalidate = load_val_data()\ntest = load_test_data()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T09:11:43.752922Z","iopub.execute_input":"2024-03-31T09:11:43.753726Z","iopub.status.idle":"2024-03-31T09:11:43.975015Z","shell.execute_reply.started":"2024-03-31T09:11:43.753687Z","shell.execute_reply":"2024-03-31T09:11:43.974134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration:","metadata":{}},{"cell_type":"code","source":"train_files = get_file_names('train')\nval_files = get_file_names('val')\ntest_files = get_file_names('test')\n\npattern = '-(\\d+).tfrec'\n\ntrain_files_sum = sum(map(lambda x: int(re.search(pattern, x).group(1)), train_files))\nval_files_sum = sum(map(lambda x: int(re.search(pattern, x).group(1)), val_files))\ntest_files_sum = sum(map(lambda x: int(re.search(pattern, x).group(1)), test_files))\n\ncategories = ['train', 'validation', 'test']\nvalues = [train_files_sum, val_files_sum, test_files_sum]\n\ncmap = plt.get_cmap('magma')\ncolors = cmap(np.linspace(0, 1, len(values)))\n\nplt.figure(figsize=(8, 6))\nbars = plt.bar(categories, values, color=colors)\n\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width() / 2., height, f'{int(height)}',\n             ha='center', va='bottom', color='black')\n\nplt.title('Number of Images')\nplt.ylabel('Sum of Numbers in Filenames')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T09:11:45.502405Z","iopub.execute_input":"2024-03-31T09:11:45.503364Z","iopub.status.idle":"2024-03-31T09:11:45.720776Z","shell.execute_reply.started":"2024-03-31T09:11:45.503328Z","shell.execute_reply":"2024-03-31T09:11:45.719959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels_ds = train.map(lambda image, label: label).unbatch()\ntrain_labels = next(iter(train_labels_ds.batch(TRAIN_SIZE))).numpy()\nlabel_indices = np.argmax(train_labels, axis=1)\n\nunique, counts = np.unique(label_indices, return_counts=True)\n\nplt.figure(figsize=(8, 6))\nbars = plt.bar(unique, counts, color=plt.get_cmap('viridis')(np.linspace(0, 1, len(unique))))\n\nplt.xticks([]) \nplt.tick_params(axis='x', length=0)  \nplt.xlabel('Labels')\nplt.title('Training Labels Distribution')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T09:11:48.501939Z","iopub.execute_input":"2024-03-31T09:11:48.502322Z","iopub.status.idle":"2024-03-31T09:12:04.020983Z","shell.execute_reply.started":"2024-03-31T09:11:48.502288Z","shell.execute_reply":"2024-03-31T09:12:04.020217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_labels_ds = validate.map(lambda image, label: label).unbatch()\nval_labels =  next(iter(val_labels_ds.batch(VAL_SIZE))).numpy()\nval_label_indices = np.argmax(val_labels, axis=1)\n\nunique, counts = np.unique(val_label_indices, return_counts=True)\n\nplt.figure(figsize=(8, 6))\nbars = plt.bar(unique, counts, color=plt.get_cmap('viridis')(np.linspace(0, 1, len(unique))))\n\nplt.xticks([]) \nplt.tick_params(axis='x', length=0)  \nplt.xlabel('Labels')\nplt.title('Validation Labels Distribution')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-31T09:12:04.022319Z","iopub.execute_input":"2024-03-31T09:12:04.022587Z","iopub.status.idle":"2024-03-31T09:12:08.060652Z","shell.execute_reply.started":"2024-03-31T09:12:04.022560Z","shell.execute_reply":"2024-03-31T09:12:08.059724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training and evaluation :\n","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    base_model = Xception(include_top=False, weights='imagenet', input_shape=(299,299,3))\n    \n    model = Sequential([\n        base_model,\n        BatchNormalization(),\n        GlobalAveragePooling2D(),\n        Dense(1024, activation='relu'),\n        Dropout(0.1),\n        Dense(512, activation='relu'),\n        Dropout(0.1),\n        Dense(256, activation='relu'),\n        Dropout(0.1),\n        Dense(104, activation='softmax')\n    ])\n    \n    model.compile(\n        optimizer='adamax',\n        loss='categorical_crossentropy',\n        metrics=[F1Score(average='macro')]\n    )\n    \n    train_history = model.fit(\n        train,\n        steps_per_epoch=100,\n        epochs=100,\n        validation_data=validate,\n        validation_steps=15\n    )\n","metadata":{"execution":{"iopub.status.busy":"2024-03-31T09:12:08.061753Z","iopub.execute_input":"2024-03-31T09:12:08.062018Z","iopub.status.idle":"2024-03-31T09:44:56.221152Z","shell.execute_reply.started":"2024-03-31T09:12:08.061993Z","shell.execute_reply":"2024-03-31T09:44:56.220031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(validate)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T09:44:56.223631Z","iopub.execute_input":"2024-03-31T09:44:56.223898Z","iopub.status.idle":"2024-03-31T09:45:00.594372Z","shell.execute_reply.started":"2024-03-31T09:44:56.223872Z","shell.execute_reply":"2024-03-31T09:45:00.593350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\n\nplt.subplot(2,1,1)\nplt.plot(train_history.history['loss'])\nplt.plot(train_history.history['val_loss'], 'ro')\nplt.title('Loss')\nplt.grid(True)\n\nplt.subplot(2,1,2)\nplt.plot(train_history.history['f1_score'])\nplt.plot(train_history.history['val_f1_score'], 'ro')\nplt.title('F1-Score')\nplt.grid(True)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T10:00:13.945471Z","iopub.execute_input":"2024-03-31T10:00:13.945850Z","iopub.status.idle":"2024-03-31T10:00:14.292597Z","shell.execute_reply.started":"2024-03-31T10:00:13.945819Z","shell.execute_reply":"2024-03-31T10:00:14.291669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = test.map(lambda idx, image: image)\npredictions_list = []\n\nfor batch_images in test_images:\n    batch_predictions = model(batch_images, training=False) \n    predictions_list.append(batch_predictions)\n\nall_predictions = np.concatenate(predictions_list, axis=0)\npredicted_classes = np.argmax(all_predictions, axis=-1)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T10:00:17.304848Z","iopub.execute_input":"2024-03-31T10:00:17.305221Z","iopub.status.idle":"2024-03-31T10:10:18.352837Z","shell.execute_reply.started":"2024-03-31T10:00:17.305175Z","shell.execute_reply":"2024-03-31T10:10:18.351749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ids_ds = test.map(lambda idx, image: idx).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(TEST_SIZE))).numpy().astype('U')\n\nsubmission = pd.DataFrame({'id': test_ids, 'label': predicted_classes})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-31T10:20:58.708008Z","iopub.execute_input":"2024-03-31T10:20:58.708973Z","iopub.status.idle":"2024-03-31T10:21:00.872377Z","shell.execute_reply.started":"2024-03-31T10:20:58.708930Z","shell.execute_reply":"2024-03-31T10:21:00.871249Z"},"trusted":true},"execution_count":null,"outputs":[]}]}